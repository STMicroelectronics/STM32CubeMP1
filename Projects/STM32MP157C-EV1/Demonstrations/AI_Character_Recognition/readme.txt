/**
  @page AI_Character_Recognition Artificial Intelligence Hand Writing Character Recognition

  @verbatim
  *************************************************************************************************
  * @file    readme.txt
  * @author  MCD Application Team
  * @brief   Description of the Artificial Intelligence Hand Writing Character Recognition example.
  *************************************************************************************************
  *
  * Copyright (c) 2021 STMicroelectronics.
  * All rights reserved.
  *
  * This software is licensed under terms that can be found in the LICENSE file
  * in the root directory of this software component.
  * If no LICENSE file comes with this software, it is provided AS-IS.
  *
  *
  *************************************************************************************************
  @endverbatim

@par Description

This project demonstrate a complex application that is running on both CPU1(CA7) and CPU2(CM4).
The application is a launcher that recognize hand writing character drawn on the touch screen in order
to execute specific actions.

CPU1 (CA7) control the touch event and the Graphic User Interface.
CPU2 (CM4) is used to offload the processing of a STM32Cube.AI pre-build Neural Network.

The communication between the CPU1(CA7) and the CPU2(CM4) is done through a Virtual UART to create an
Inter-Processor Communication channel seen as a TTY device in Linux.
The implementation is based on:
    * RPMSG framework on CPU1(CA7) side
    * and OpenAMP MW on the CPU2(CM4) side

OpenAMP MW uses the following HW resources
    * IPCC peripheral for event signal (mailbox) between CPU1(CA7) and CPU2(CM4)
    * MCUSRAM peripheral for buffer communications (virtio buffers) between CPU1(CA7) and CPU2(CM4)

CRC2 is initialized and used by AI library to check that we are on a ST device.  

A communication protocol has been defined between the CPU1(CA7 and the CPU2(CM4).
The data frames exchanged have the follwowing structure:
    ----------------------------------------------------------------
    | msg ID | data Length | data Byte 1 | ... | data Byte n | CRC |
    ----------------------------------------------------------------

    - 3 types of message could be received by CPU2(CM4):
        * Set the Neural Network input type (0x20, 0x01, data, CRC)
            * data = 0 => NN input is letter or digit
            * data = 1 => NN input is letter only
            * data = 2 => NN input is digit only

        * Provide the touch screen coordinate (0x20, n, data_x1, data_y1, ... , data_xn, data_yn, CRC)
            * n       => the number of coordinate points
            * data_xn => x coordinate of the point n
            * data_yn => y coordinate of the point n

        * Start ai nn processing (0x22, 0x00, CRC)

    - 4 types of acknowledges could be received on CPU1(CA7) side:
        * Bad acknowledge (0xFF, 0x00, CRC)

        * Good acknowledge (0xF0, 0x00, CRC)

        * Touch screen acknowledge (0xF0, 0x01, n, CRC)
            * n => number of screen coordinate points acknowledged

        * AI processing result acknowledge (0xF0, 0x04, char, accuracy, time_1, time_2, CRC)
            * char     => this is the recognized letter (or digit)
            * accuracy => this is the confidence expressed in percentage
            * time_1   => upper Bytes of the time (word) expressed in ms
            * time_2   => lower Bytes of the time (word) expressed in ms

On CPU2(CM4) side:
    - CPU2(CM4) initialize OPenAMP MW which initializes/configures IPCC peripheral through HAL
      and setup openamp-rpmsg framwork infrastructure
    - CPU2(CM4) creates 1 rpmsg channels for 1 virtual UART instance UART0
    - CPU2(CM4) initialize the Character Recognition Neural Network
    - CPU2(CM4) is waiting for messages from CPU1(CA7) on this channels
    - When CPU2(CM4) receives a message on 1 Virtual UART instance/rpmsg channel, it processes the message
      to execute the associated action:
        * set the NN input type to the desire value
        * or register the touch event coordinate to generate the picture that will be processed by the NN
        * or start the NN processing and wait for the results
    - On every previous action, the CPU(CM4) is sending back to the CPU1(CA7) and acknowledge already defined
      above.

On CPU1(CA7) side:
    - CPU1(CA7) open the input event to register the touch events generated by the user's finger drawing
    - CPU1(CA7) configure the input type (Letter only) of the Neural Network running on the CPU2(CM4) by
      sending a message throught the virtual TTY communication channel
    - when the drawing is finished, CPU1(CA7) process the touch event data and send it to the CPU2(CM4)
    - CPU1(CA7) start the Neural Network processing wait for the result and display the recognized character on
      the diplay

Some information about the Character Recognition Neural Network:
    The Character Recognition Neural Network used is a Keras model processed by Cube.AI to generate the executable
    that can be run on the CPU2(CM4).
    The Keras model used is located in the root directory of this project:
      model-ABC123-112.h5
    This model has been used in Cube.AI to generate the Neural Network binary.
    The model accept as input a 28x28 picture encoded with float in black and white (black = 0.0 or White = 1.0).
    The output layer of the Neural Network contains 36 neurons (A -> Z and 0 -> 9).

Notes:
    - It requires Linux console to run the application.
    - CM4 logging is redirected in Shared memory in MCUSRAM and can be displayed using following command:
          cat /sys/kernel/debug/remoteproc/remoteproc0/trace0

    Following command should be done in Linux console on CA7 to run the example :
    > /usr/local/demo/bin/ai_char_reco_launcher /usr/local/demo/bin/apps_launcher_example.sh

    You are ready to draw letter on the touch screen

@note Care must be taken when using HAL_Delay(), this function provides accurate
      delay (in milliseconds) based on variable incremented in HAL time base ISR.
      This implies that if HAL_Delay() is called from a peripheral ISR process, then
      the HAL time base interrupt must have higher priority (numerically lower) than
      the peripheral interrupt. Otherwise the caller ISR process will be blocked.
      To change the HAL time base interrupt priority you have to use HAL_NVIC_SetPriority()
      function.

@note The application needs to ensure that the HAL time base is always set to 1 millisecond
      to have correct HAL operation.

@par Directory contents
    - AI_Character_Recognition/AI/lib/network_runtime.a     Neural Network library generated by Cube.AI
    - AI_Character_Recognition/Inc/app_x-cube-ai.h          ai application header file
    - AI_Character_Recognition/Inc/lock_resource.h          lock resource header file
    - AI_Character_Recognition/Inc/main.h                   Main program header file
    - AI_Character_Recognition/Inc/mbox_ipcc.h              mailbox_ipcc_if.c MiddleWare configuration header file
    - AI_Character_Recognition/Inc/openamp_conf.h           Configuration file for OpenAMP MW
    - AI_Character_Recognition/Inc/openamp.h                User OpenAMP init header file
    - AI_Character_Recognition/Inc/rsc_table.h              Resource_table for OpenAMP header file
    - AI_Character_Recognition/Inc/log.h                    Logging header file
    - AI_Character_Recognition/Inc/stm32mp1xx_hal_conf.h    HAL Library Configuration file
    - AI_Character_Recognition/Inc/stm32mp1xx_it.h          Interrupt handlers header file
    - AI_Character_Recognition/Src/app_x-cube-ai.c          ai application
    - AI_Character_Recognition/Src/lock_resource.c          lock resource functions
    - AI_Character_Recognition/Src/main.c                   Main program
    - AI_Character_Recognition/Src/mbox_ipcc.c              mailbox_ipcc_if.c MiddleWare configuration
    - AI_Character_Recognition/Src/openamp.c                User OpenAMP init
    - AI_Character_Recognition/Src/rsc_table.c              Resource_table for OpenAMP
    - AI_Character_Recognition/Inc/log.h                    Logging service file
    - AI_Character_Recognition/Src/stm32mp1xx_hal_msp.c     HAL configuration function
    - AI_Character_Recognition/Src/stm32mp1xx_it.c          Interrupt handlers
    - AI_Character_Recognition/Src/system_stm32mp1xx.c      STM32MP1xx system clock configuration file

@par Hardware and Software environment

  - This example runs on STM32MP157CAAx devices.

  - This example has been tested with STM32MP157C-DK2 and STM32MP157C-EV1 board and can be
    easily tailored to any other supported device and development board.

@par How to use it ?

In order to make the program work, you must do the following:
 - Open your preferred toolchain
 - Rebuild all files and load your image into target memory
 - Run the demonstrator by executing /usr/local/demo/bin/ai_char_reco_launcher /usr/local/demo/bin/apps_launcher.sh
   on the CPU1(CA7) console.

@par About the Neural Network
  The Neural Network use as been inspired by:
  https://www.nist.gov/itl/iad/image-group/emnist-dataset
  and
  http://yann.lecun.com/exdb/mnist/

  The pre-build Neural Network library has been generated using STM32Cube.AI that will be available soon.


 * <h3><center>&copy; COPYRIGHT STMicroelectronics</center></h3>
 */
